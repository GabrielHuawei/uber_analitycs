{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from CloudBucket import CloudBucket\n",
    "import httpx\n",
    "import io\n",
    "from decouple import config\n",
    "import pandas as pd\n",
    "import io\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_location = 'obs.sa-brazil-1.myhuaweicloud.com'\n",
    "access_key_id = 'UUPFWV82Q3J8VYVHNZBQ'\n",
    "secret_access_key = 'Ib4bDYbx5jdLrjDQulpiQRSKGPer5ffkx5ppi9ug'\n",
    "with CloudBucket(access_key_id=access_key_id, secret_access_key=secret_access_key, server_location=server_location) as client:\n",
    "    bytes_file_response = client.get_binary_file(bucketName='test-datalake', file_name='uber_data.csv')\n",
    "    df = pd.read_csv(io.BytesIO(bytes_file_response.body.buffer), sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   VendorID               100000 non-null  int64  \n",
      " 1   tpep_pickup_datetime   100000 non-null  object \n",
      " 2   tpep_dropoff_datetime  100000 non-null  object \n",
      " 3   passenger_count        100000 non-null  int64  \n",
      " 4   trip_distance          100000 non-null  float64\n",
      " 5   pickup_longitude       100000 non-null  float64\n",
      " 6   pickup_latitude        100000 non-null  float64\n",
      " 7   RatecodeID             100000 non-null  int64  \n",
      " 8   store_and_fwd_flag     100000 non-null  object \n",
      " 9   dropoff_longitude      100000 non-null  float64\n",
      " 10  dropoff_latitude       100000 non-null  float64\n",
      " 11  payment_type           100000 non-null  int64  \n",
      " 12  fare_amount            100000 non-null  float64\n",
      " 13  extra                  100000 non-null  float64\n",
      " 14  mta_tax                100000 non-null  float64\n",
      " 15  tip_amount             100000 non-null  float64\n",
      " 16  tolls_amount           100000 non-null  float64\n",
      " 17  improvement_surcharge  100000 non-null  float64\n",
      " 18  total_amount           100000 non-null  float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\g50034179\\Documents\\studies\\uber_analytics\\assets\\uber_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.name = \"Id\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataFrame type -> transform to datatime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   VendorID               100000 non-null  int64         \n",
      " 1   tpep_pickup_datetime   100000 non-null  datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  100000 non-null  datetime64[ns]\n",
      " 3   passenger_count        100000 non-null  int64         \n",
      " 4   trip_distance          100000 non-null  float64       \n",
      " 5   pickup_longitude       100000 non-null  float64       \n",
      " 6   pickup_latitude        100000 non-null  float64       \n",
      " 7   RatecodeID             100000 non-null  int64         \n",
      " 8   store_and_fwd_flag     100000 non-null  object        \n",
      " 9   dropoff_longitude      100000 non-null  float64       \n",
      " 10  dropoff_latitude       100000 non-null  float64       \n",
      " 11  payment_type           100000 non-null  int64         \n",
      " 12  fare_amount            100000 non-null  float64       \n",
      " 13  extra                  100000 non-null  float64       \n",
      " 14  mta_tax                100000 non-null  float64       \n",
      " 15  tip_amount             100000 non-null  float64       \n",
      " 16  tolls_amount           100000 non-null  float64       \n",
      " 17  improvement_surcharge  100000 non-null  float64       \n",
      " 18  total_amount           100000 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(12), int64(4), object(1)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "def test_df_datetype(df: pd.DataFrame) -> None:\n",
    "    assert all([data_type == 'datetime64[ns]' for data_type in df[['tpep_pickup_datetime', 'tpep_dropoff_datetime']].dtypes])\n",
    "\n",
    "test_df_datetype(df)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the duplicates and assing a PK to 'trip_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df['trip_id'] = df.index\n",
    "df.head()\n",
    "\n",
    "def test_trip_id(df: pd.DataFrame) -> None:\n",
    "    def check_numeric_progression(id_list):\n",
    "        initial_value = id_list[0]\n",
    "        for idx, value in enumerate(id_list):\n",
    "            if value != initial_value + idx:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    assert all(isinstance(id, int) for id in df['trip_id'])\n",
    "    assert check_numeric_progression(df['trip_id'])\n",
    "\n",
    "test_trip_id(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the datetime_dim schema with pandas & testing the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_dim = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime']].reset_index(drop=True)\n",
    "datetime_dim['tpep_pickup_datetime'] = datetime_dim['tpep_pickup_datetime']\n",
    "datetime_dim['pick_hour'] = datetime_dim['tpep_pickup_datetime'].dt.hour\n",
    "datetime_dim['pick_day'] = datetime_dim['tpep_pickup_datetime'].dt.day\n",
    "datetime_dim['pick_month'] = datetime_dim['tpep_pickup_datetime'].dt.month\n",
    "datetime_dim['pick_year'] = datetime_dim['tpep_pickup_datetime'].dt.year\n",
    "datetime_dim['pick_weekday'] = datetime_dim['tpep_pickup_datetime'].dt.weekday\n",
    "\n",
    "datetime_dim['tpep_dropoff_datetime'] = datetime_dim['tpep_dropoff_datetime']\n",
    "datetime_dim['drop_hour'] = datetime_dim['tpep_dropoff_datetime'].dt.hour\n",
    "datetime_dim['drop_day'] = datetime_dim['tpep_dropoff_datetime'].dt.day\n",
    "datetime_dim['drop_month'] = datetime_dim['tpep_dropoff_datetime'].dt.month\n",
    "datetime_dim['drop_year'] = datetime_dim['tpep_dropoff_datetime'].dt.year\n",
    "datetime_dim['drop_weekday'] = datetime_dim['tpep_dropoff_datetime'].dt.weekday\n",
    "\n",
    "datetime_dim['datetime_id'] = datetime_dim.index\n",
    "datetime_dim.head(20)\n",
    "\n",
    "def test_datetime_dim(datatime_dim: pd.DataFrame) -> None:\n",
    "    assert not datatime_dim.isnull().values.any()\n",
    "    assert all([len(str(item)) == 4 and isinstance(item, int) for item in datetime_dim['pick_year']])\n",
    "    assert all([isinstance(date, datetime) for date in datetime_dim['tpep_pickup_datetime']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['pick_hour']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['pick_day']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['pick_month']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['pick_year']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['pick_weekday']])\n",
    "\n",
    "    assert all([len(str(item)) == 4 and isinstance(item, int) for item in datetime_dim['drop_year']])\n",
    "    assert all([isinstance(date, datetime) for date in datetime_dim['tpep_dropoff_datetime']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['drop_hour']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['drop_day']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['drop_month']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['drop_year']])\n",
    "    assert all([isinstance(item, int) for item in datetime_dim['drop_weekday']])\n",
    "\n",
    "datetime_dim = datetime_dim[['datetime_id', 'tpep_pickup_datetime', 'pick_hour', 'pick_day', 'pick_month', 'pick_year', 'pick_weekday',\n",
    "                             'tpep_dropoff_datetime', 'drop_hour', 'drop_day', 'drop_month', 'drop_year', 'drop_weekday']]\n",
    "\n",
    "test_datetime_dim(datetime_dim)\n",
    "datetime_dim['tpep_pickup_datetime'] = datetime_dim['tpep_pickup_datetime'].dt.strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "datetime_dim['tpep_dropoff_datetime'] = datetime_dim['tpep_dropoff_datetime'].dt.strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datetime_dim.head()\n",
    "# datetime_dim['']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the passenger_count_dim schema with pandas & testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_count_dim = df[['passenger_count']].reset_index(drop=True)\n",
    "passenger_count_dim['passenger_count_id'] = passenger_count_dim.index\n",
    "passenger_count_dim = passenger_count_dim[['passenger_count_id', 'passenger_count']]\n",
    "\n",
    "def test_passenger_count_dim(passenger_count_dim: pd.DataFrame) -> None:\n",
    "    assert not passenger_count_dim.isnull().values.any()\n",
    "    assert all([isinstance(item, int) for item in passenger_count_dim['passenger_count']])\n",
    "    assert all([isinstance(item, int) for item in passenger_count_dim['passenger_count_id']])    \n",
    "\n",
    "test_passenger_count_dim(passenger_count_dim)\n",
    "passenger_count_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_distance_dim = df[['trip_distance']].reset_index(drop=True)\n",
    "trip_distance_dim['trip_distance_id'] = trip_distance_dim.index\n",
    "trip_distance_dim = trip_distance_dim[['trip_distance_id', 'trip_distance']]\n",
    "\n",
    "def test_trip_distance_dim(trip_distance_dim: pd.DataFrame) -> None:\n",
    "    assert not trip_distance_dim.isnull().values.any()\n",
    "    assert all([isinstance(item, int) for item in trip_distance_dim['trip_distance_id']])\n",
    "    assert all([isinstance(item, float) for item in trip_distance_dim['trip_distance']])    \n",
    "\n",
    "test_trip_distance_dim(trip_distance_dim)\n",
    "trip_distance_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the rate_code_dim schema with pandas & testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_code_type = {\n",
    "    1:\"Standard rate\",\n",
    "    2:\"JFK\",\n",
    "    3:\"Newark\",\n",
    "    4:\"Nassau or Westchester\",\n",
    "    5:\"Negotiated fare\",\n",
    "    6:\"Group ride\"\n",
    "}\n",
    "\n",
    "rate_code_dim = df[['RatecodeID']].reset_index(drop=True)\n",
    "rate_code_dim['rate_code_id'] = rate_code_dim.index\n",
    "rate_code_dim['rate_code_name'] = rate_code_dim['RatecodeID'].map(rate_code_type)\n",
    "rate_code_dim = rate_code_dim[['rate_code_id','RatecodeID','rate_code_name']]\n",
    "\n",
    "def test_rate_code_dim(rate_code_dim: pd.DataFrame) -> None:\n",
    "    assert all([isinstance(id, int) for id in rate_code_dim['rate_code_id']])\n",
    "    assert all([isinstance(id, int) for id in rate_code_dim['RatecodeID']])\n",
    "    assert all([rate_code in rate_code_type.values() for rate_code in rate_code_dim['rate_code_name']])\n",
    "\n",
    "test_rate_code_dim(rate_code_dim)\n",
    "rate_code_dim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the pickup_location_dim schema with pandas & testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_location_dim = df[['pickup_longitude', 'pickup_latitude']].reset_index(drop=True)\n",
    "pickup_location_dim['pickup_location_id'] = pickup_location_dim.index\n",
    "pickup_location_dim = pickup_location_dim[['pickup_location_id','pickup_latitude','pickup_longitude']] \n",
    "\n",
    "def test_pickup_location_dim(pickup_location_dim: pd.DataFrame) -> None:\n",
    "    assert all([isinstance(id, int) for id in pickup_location_dim['pickup_location_id']])\n",
    "    assert all([isinstance(latitude, float) for latitude in pickup_location_dim['pickup_latitude']])\n",
    "    assert all([isinstance(longitude, float) for longitude in pickup_location_dim['pickup_longitude']])\n",
    "\n",
    "test_pickup_location_dim(pickup_location_dim)\n",
    "\n",
    "pickup_location_dim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the dropoff_location_dim schema with pandas & testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoff_location_dim = df[['dropoff_longitude', 'dropoff_latitude']].reset_index(drop=True)\n",
    "dropoff_location_dim['dropoff_location_id'] = dropoff_location_dim.index\n",
    "dropoff_location_dim = dropoff_location_dim[['dropoff_location_id','dropoff_latitude','dropoff_longitude']]\n",
    "\n",
    "def test_dropoff_location_dim(dropoff_location_dim: pd.DataFrame) -> None:\n",
    "    assert all([isinstance(id, int) for id in dropoff_location_dim['dropoff_location_id']])\n",
    "    assert all([isinstance(latitude, float) for latitude in dropoff_location_dim['dropoff_latitude']])\n",
    "    assert all([isinstance(longitude, float) for longitude in dropoff_location_dim['dropoff_longitude']])\n",
    "\n",
    "test_dropoff_location_dim(dropoff_location_dim)\n",
    "dropoff_location_dim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_type_name = {\n",
    "    1:\"Credit card\",\n",
    "    2:\"Cash\",\n",
    "    3:\"No charge\",\n",
    "    4:\"Dispute\",\n",
    "    5:\"Unknown\",\n",
    "    6:\"Voided trip\"\n",
    "}\n",
    "\n",
    "payment_type_dim = df[['payment_type']].reset_index(drop=True)\n",
    "payment_type_dim['payment_type_id'] = payment_type_dim.index\n",
    "payment_type_dim['payment_type_name'] = payment_type_dim['payment_type'].map(payment_type_name)\n",
    "payment_type_dim = payment_type_dim[['payment_type_id', 'payment_type', 'payment_type_name']]\n",
    "\n",
    "\n",
    "def test_payment_type_dim(payment_type_dim: pd.DataFrame) -> None:\n",
    "    assert all([isinstance(value, int) for value in payment_type_dim['payment_type']])\n",
    "    assert all([isinstance(value, int) for value in payment_type_dim['payment_type_id']])\n",
    "    assert any([payment_type in payment_type_name.values() for payment_type in payment_type_dim['payment_type_name']])\n",
    "\n",
    "test_payment_type_dim(payment_type_dim)\n",
    "payment_type_dim\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling the fact_table schema with pandas, concatenating the dim_tables into & testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fact_table = df.merge(passenger_count_dim, left_on='trip_id', right_on='passenger_count_id') \\\n",
    "#              .merge(trip_distance_dim, left_on='trip_id', right_on='trip_distance_id') \\\n",
    "#              .merge(rate_code_dim, left_on='trip_id', right_on='rate_code_id') \\\n",
    "#              .merge(pickup_location_dim, left_on='trip_id', right_on='pickup_location_id') \\\n",
    "#              .merge(dropoff_location_dim, left_on='trip_id', right_on='dropoff_location_id')\\\n",
    "#              .merge(datetime_dim, left_on='trip_id', right_on='datetime_id') \\\n",
    "#              .merge(payment_type_dim, left_on='trip_id', right_on='payment_type_id') \\\n",
    "#              [['trip_id','VendorID', 'datetime_id', 'passenger_count_id',\n",
    "#                'trip_distance_id', 'rate_code_id', 'store_and_fwd_flag', 'pickup_location_id', 'dropoff_location_id',\n",
    "#                'payment_type_id', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "#                'improvement_surcharge', 'total_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fact_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for value in dict(df.dtypes).values():\n",
    "#     print(f\"\\'{str(value).replace('dtype(', '').replace('),', '')}\\',\")\n",
    "df_dtypes = [\n",
    "    'int64',\n",
    "    'datetime64[ns]',\n",
    "    'datetime64[ns]',\n",
    "    'int64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'int64',\n",
    "    'object',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'int64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'float64',\n",
    "    'int64',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_code_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'assets/uber_data.csv')\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df['trip_id'] = df.index\n",
    "df.index.name = \"Id\"\n",
    "df['payment_type_name'] = df['payment_type'].map(payment_type_name)\n",
    "df['rate_code_name'] = df['RatecodeID'].map(rate_code_type)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df.to_csv(r'assets/uber_refined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huawei-autotools-h-O394pJ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
